{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1ZGSTh_f2y5f-WOjgf1wKq_oUqjCGpfEC",
      "authorship_tag": "ABX9TyPEmCJyj/lvfuddtD0w0e7Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sudhakarkrish2002/-SIP8/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n"
      ],
      "metadata": {
        "id": "FbFiGmNeltCO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation for the training set\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Rescale validation and test sets\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load training set\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/archive/test',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Load validation set\n",
        "validation_set = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/archive/valid',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imj8iAwwl0FY",
        "outputId": "578eb90b-e987-464c-b600-7a17314d05f9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 150 images belonging to 30 classes.\n",
            "Found 150 images belonging to 30 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')  # Assuming 3 classes of balls\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "Ag91aIJXm05l"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Data augmentation for the training set\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Rescale validation and test sets\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load training set\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/archive/test',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Load validation set\n",
        "validation_set = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/archive/valid',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Define the CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(30, activation='softmax')  # Update to match the number of classes\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    training_set,\n",
        "    steps_per_epoch=training_set.samples // training_set.batch_size,\n",
        "    epochs=50,\n",
        "    validation_data=validation_set,\n",
        "    validation_steps=validation_set.samples // validation_set.batch_size\n",
        ")\n",
        "\n",
        "# Load test set\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/archive/test',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(test_set)\n",
        "print(f'Test Accuracy: {accuracy*100:.2f}%')\n",
        "\n",
        "# Save the model\n",
        "model.save('ball_classification_model.h5')\n",
        "\n",
        "# Load the model\n",
        "loaded_model = tf.keras.models.load_model('ball_classification_model.h5')\n",
        "\n",
        "# Evaluate the loaded model\n",
        "loss, accuracy = loaded_model.evaluate(test_set)\n",
        "print(f'Loaded Model Test Accuracy: {accuracy*100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsXZ0WfrrX88",
        "outputId": "66d52b1a-e068-4b28-8da0-ac421039d9e9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 150 images belonging to 30 classes.\n",
            "Found 150 images belonging to 30 classes.\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 5s 1s/step - loss: 3.4376 - accuracy: 0.0339 - val_loss: 3.3932 - val_accuracy: 0.0391\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 2s 634ms/step - loss: 3.4107 - accuracy: 0.0169 - val_loss: 3.3978 - val_accuracy: 0.0312\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 3s 763ms/step - loss: 3.3865 - accuracy: 0.0678 - val_loss: 3.3832 - val_accuracy: 0.0312\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 2s 685ms/step - loss: 3.3753 - accuracy: 0.0678 - val_loss: 3.3669 - val_accuracy: 0.0859\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 3s 728ms/step - loss: 3.3295 - accuracy: 0.1017 - val_loss: 3.3212 - val_accuracy: 0.1406\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 3s 744ms/step - loss: 3.2779 - accuracy: 0.1102 - val_loss: 3.2847 - val_accuracy: 0.1016\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 2s 661ms/step - loss: 3.2172 - accuracy: 0.1441 - val_loss: 3.2350 - val_accuracy: 0.1250\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 2s 664ms/step - loss: 3.2296 - accuracy: 0.0678 - val_loss: 3.2107 - val_accuracy: 0.0938\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 3s 763ms/step - loss: 3.1944 - accuracy: 0.1094 - val_loss: 3.2029 - val_accuracy: 0.0703\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 4s 942ms/step - loss: 3.2100 - accuracy: 0.0932 - val_loss: 3.2331 - val_accuracy: 0.0703\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 3s 801ms/step - loss: 3.1327 - accuracy: 0.1441 - val_loss: 3.1722 - val_accuracy: 0.0781\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 3s 805ms/step - loss: 3.0110 - accuracy: 0.1102 - val_loss: 3.1265 - val_accuracy: 0.1094\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 3s 754ms/step - loss: 2.9118 - accuracy: 0.1864 - val_loss: 3.1502 - val_accuracy: 0.1094\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 2.9449 - accuracy: 0.1780 - val_loss: 3.0319 - val_accuracy: 0.1406\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 2s 620ms/step - loss: 2.8567 - accuracy: 0.1695 - val_loss: 2.9784 - val_accuracy: 0.1328\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 2s 638ms/step - loss: 2.7692 - accuracy: 0.2458 - val_loss: 2.9432 - val_accuracy: 0.1484\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 3s 765ms/step - loss: 2.6466 - accuracy: 0.2373 - val_loss: 2.9253 - val_accuracy: 0.1172\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 3s 728ms/step - loss: 2.5910 - accuracy: 0.1949 - val_loss: 2.9967 - val_accuracy: 0.1484\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 3s 784ms/step - loss: 2.6783 - accuracy: 0.2656 - val_loss: 3.0066 - val_accuracy: 0.1406\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 2s 650ms/step - loss: 2.4603 - accuracy: 0.2188 - val_loss: 2.9451 - val_accuracy: 0.1641\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 2s 641ms/step - loss: 2.5958 - accuracy: 0.2288 - val_loss: 2.8700 - val_accuracy: 0.2188\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 3s 698ms/step - loss: 2.5285 - accuracy: 0.3136 - val_loss: 2.8654 - val_accuracy: 0.2266\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 3s 806ms/step - loss: 2.2973 - accuracy: 0.3305 - val_loss: 2.9575 - val_accuracy: 0.1953\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 2s 600ms/step - loss: 2.2158 - accuracy: 0.3644 - val_loss: 2.8715 - val_accuracy: 0.2109\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 2s 676ms/step - loss: 2.0506 - accuracy: 0.4153 - val_loss: 2.9483 - val_accuracy: 0.2188\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 3s 756ms/step - loss: 2.0804 - accuracy: 0.3750 - val_loss: 2.8549 - val_accuracy: 0.1953\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 3s 762ms/step - loss: 1.9642 - accuracy: 0.4531 - val_loss: 2.9113 - val_accuracy: 0.2031\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 3s 662ms/step - loss: 2.0598 - accuracy: 0.3672 - val_loss: 2.7229 - val_accuracy: 0.2422\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 1.9377 - accuracy: 0.4068 - val_loss: 2.7808 - val_accuracy: 0.2266\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 4s 1s/step - loss: 2.0624 - accuracy: 0.3438 - val_loss: 2.8250 - val_accuracy: 0.2578\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 3s 861ms/step - loss: 1.7585 - accuracy: 0.4492 - val_loss: 2.5449 - val_accuracy: 0.2734\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 3s 734ms/step - loss: 1.7833 - accuracy: 0.4661 - val_loss: 2.7052 - val_accuracy: 0.2344\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 3s 726ms/step - loss: 1.6893 - accuracy: 0.5000 - val_loss: 2.5870 - val_accuracy: 0.2969\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 2s 647ms/step - loss: 1.7441 - accuracy: 0.4746 - val_loss: 2.7944 - val_accuracy: 0.2734\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 4s 918ms/step - loss: 1.7215 - accuracy: 0.5169 - val_loss: 3.1661 - val_accuracy: 0.2109\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 2s 656ms/step - loss: 1.9081 - accuracy: 0.4407 - val_loss: 2.8473 - val_accuracy: 0.2656\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 1.8016 - accuracy: 0.4153 - val_loss: 2.6937 - val_accuracy: 0.2891\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 3s 753ms/step - loss: 1.4723 - accuracy: 0.5847 - val_loss: 3.0356 - val_accuracy: 0.2656\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 3s 763ms/step - loss: 1.4978 - accuracy: 0.5254 - val_loss: 2.7332 - val_accuracy: 0.2656\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 3s 687ms/step - loss: 1.3619 - accuracy: 0.6017 - val_loss: 2.6677 - val_accuracy: 0.2734\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 2s 639ms/step - loss: 1.2988 - accuracy: 0.5847 - val_loss: 3.1134 - val_accuracy: 0.2656\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 3s 810ms/step - loss: 1.5232 - accuracy: 0.5593 - val_loss: 2.8187 - val_accuracy: 0.2891\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 1.3958 - accuracy: 0.6102 - val_loss: 2.9470 - val_accuracy: 0.2500\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 4s 979ms/step - loss: 1.4585 - accuracy: 0.5625 - val_loss: 2.7929 - val_accuracy: 0.2812\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 2s 626ms/step - loss: 1.2403 - accuracy: 0.6610 - val_loss: 2.8387 - val_accuracy: 0.2500\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 3s 753ms/step - loss: 1.4669 - accuracy: 0.5763 - val_loss: 2.9576 - val_accuracy: 0.2734\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 3s 730ms/step - loss: 1.2211 - accuracy: 0.6186 - val_loss: 2.8259 - val_accuracy: 0.2812\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 3s 722ms/step - loss: 1.3734 - accuracy: 0.5847 - val_loss: 2.8453 - val_accuracy: 0.3125\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 3s 784ms/step - loss: 1.2127 - accuracy: 0.5781 - val_loss: 2.6959 - val_accuracy: 0.3125\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 2s 622ms/step - loss: 1.0921 - accuracy: 0.6102 - val_loss: 2.8998 - val_accuracy: 0.2812\n",
            "Found 150 images belonging to 30 classes.\n",
            "5/5 [==============================] - 1s 172ms/step - loss: 0.4210 - accuracy: 0.9267\n",
            "Test Accuracy: 92.67%\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 0.4210 - accuracy: 0.9267\n",
            "Loaded Model Test Accuracy: 92.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test set\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/archive/test',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMLn5RVOwaiM",
        "outputId": "f71fed31-1da1-4d91-dff7-5c8ca5bf76ae"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 150 images belonging to 30 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test set\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/archive/test',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(test_set)\n",
        "print(f'Test Accuracy: {accuracy*100:.2f}%')\n",
        "\n",
        "# Save the model\n",
        "model.save('ball_classification_model.h5')\n",
        "\n",
        "# Load the model\n",
        "loaded_model = tf.keras.models.load_model('ball_classification_model.h5')\n",
        "\n",
        "# Evaluate the loaded model\n",
        "loss, accuracy = loaded_model.evaluate(test_set)\n",
        "print(f'Loaded Model Test Accuracy: {accuracy*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOTQClKLy8Sz",
        "outputId": "5cdc9792-0189-4f86-e20f-45afb04aafa0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 150 images belonging to 30 classes.\n",
            "5/5 [==============================] - 1s 163ms/step - loss: 0.4210 - accuracy: 0.9267\n",
            "Test Accuracy: 92.67%\n",
            "5/5 [==============================] - 1s 166ms/step - loss: 0.4210 - accuracy: 0.9267\n",
            "Loaded Model Test Accuracy: 92.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model('ball_classification_model.h5')\n",
        "\n",
        "def load_and_preprocess_image(img_path):\n",
        "    # Load the image\n",
        "    img = image.load_img(img_path, target_size=(64, 64))\n",
        "\n",
        "    # Convert the image to a numpy array\n",
        "    img_array = image.img_to_array(img)\n",
        "\n",
        "    # Expand dimensions to match the model's input shape\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Rescale the image (assuming you rescaled your training data by 1./255)\n",
        "    img_array = img_array / 255.0\n",
        "\n",
        "    return img_array\n",
        "\n",
        "def classify_image(model, img_path, class_names):\n",
        "    # Preprocess the image\n",
        "    img_array = load_and_preprocess_image(img_path)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(img_array)\n",
        "\n",
        "    # Get the index of the class with the highest probability\n",
        "    predicted_class_index = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Check if predicted index is within the bounds of class_names\n",
        "    if predicted_class_index[0] < len(class_names):\n",
        "        # Get the class label\n",
        "        predicted_class_label = class_names[predicted_class_index[0]]\n",
        "        return predicted_class_label\n",
        "    else:\n",
        "        return \"Unknown Class\" # Return a message if the predicted class is not in your list\n",
        "\n",
        "# Define the class names\n",
        "class_names = ['soccer_ball', 'basketball', 'tennis_ball','baseball','beachballs','billiard_balls','bowling_ball','brass','buckeyballs','cannon_ball','chrochet_ball','cricket_ball','crystal_ball','eyeballs','football','golf_ball','marble','meat_ball','medicine_ball','paint_balls','pokeman_balls','puffballs','rubberband_ball','screwballs','sepak_takraw_ball','tether_ball','volley_ball','water_polo_ball','wiffle_ball','wrecking_ball']\n",
        "\n",
        "# Path to the input image\n",
        "img_path = '/content/drive/MyDrive/archive/test/wiffle ball/1.jpg'\n",
        "\n",
        "# Classify the image\n",
        "predicted_class = classify_image(model, img_path, class_names)\n",
        "\n",
        "print(f'The image is classified as: {predicted_class}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0URAeWB553oO",
        "outputId": "3c1800a1-07a5-415e-91b7-965b2af11a14"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 95ms/step\n",
            "The image is classified as: wiffle_ball\n"
          ]
        }
      ]
    }
  ]
}